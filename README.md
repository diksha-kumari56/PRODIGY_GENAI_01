# PRODIGY_GENAI_01 - Text Generation using GPT-2

## ðŸ’¼ Task
This is Task 01 of my Generative AI Internship at *Prodigy Infotech*.  
In this task, I built a simple text generation system using the *GPT-2* language model.

## ðŸ›  What I Did
- Loaded the pre-trained GPT-2 model from Hugging Face
- Used a custom prompt to generate creative and coherent text
- Displayed results directly in the notebook

## ðŸ“¸ Output Screenshot
ðŸ“„ [Click here to view the output screenshot (PDF)](Task%201%20genai.pdf)

## ðŸ§° Tools & Libraries Used
- Python
- Hugging Face Transformers
- Google Colab
- PyTorch (optional backend)

## ðŸ“š What I Learned
- How language models like GPT-2 generate human-like text
- Basics of using Hugging Faceâ€™s Transformer library
- Prompt engineering for meaningful outputs

## ðŸ”— Repository Info
- Repository Name: PRODIGY_GENAI_01
- Track: Generative AI
- Task Number: 01

## ðŸ™‹â€â™€ About Me
Hi! I'm Diksha Kumari, currently exploring the world of AI and machine learning through hands-on internships and projects.

ðŸ”— Connect with me on [LinkedIn]https://www.linkedin.com/in/diksha-kumari-562b94327?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app

---

> âœ¨ Thank you *Prodigy Infotech* for this great learning opportunity!
